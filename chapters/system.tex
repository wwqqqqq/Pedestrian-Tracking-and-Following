% !TeX root = ../main.tex

\chapter{以可佳机器人为基础的行人追踪系统}

\section{输入设备}

\subsection{Kinect}

  Kinect深度相机可以同时提供RGB图像和深度图像。

  使用RGB-D相机Kinect作为彩色图像和深度信息的输入，而Kinect的深度图像只能有效判断80厘米之外的物体的距离，且由于Kinect通过红外发射器和红外摄像头来获得深度信息，所以受阳光照射的影响较大，所以在实际使用中，Kinect深度图像可能会出现不稳定和空洞现象。

  对于Kinect的深度图像在近距离精度较低的现象，考虑在较近距离内使用2D激光进行行人的3D位置判别。对于Kinect的空洞现象，考虑使用KinectFusion算法\cite{newcombe2011kinectfusion}，将深度图像投影到RGB图像中，以进行对相机视野中场景的3D重建。

\subsection{2D激光}

  由于本文中的行人检测与追踪算法主要使用了视觉信息，所以这里2D激光主要用于建图、定位和导航。定位和导航在本文中不是主要内容，所以不再特别赘述。

\section{视觉追踪系统}

\subsection{总体架构}

\subsection{目标人物注册}
1. 使用OpenPose系统找到目标人物

给人物设定一个初始的手势，由OpenPose系统识别出人物的骨架，进而提取出视野中所有人物的姿势。如要求目标人物将一只手举起，直到机器人识别出目标人物，判断出追踪区域（Region of Interest, ROI），并提示“识别成功”，即开始追踪。

2. 建立一个判别器：根据已有的ROI作为正样本，随机提取背景作为负样本，通过在线学习拟合出一个分类器。该判别器的作用是当追踪失去目标或出错时，当再在图像中检测到一个新人物时，判断对方是否是一开始的目标人物。

\subsection{行人追踪}

1. 使用KFC和CSRT，根据“目标人物注册”中得到的ROI进行目标追踪。

\subsection{目标丢失恢复}

1. 全局扫描找到行人，结合“目标人物注册”中的判别器，判断是否是目标人物。

2. 结合目标人物最后出现的位置，类似TLD？

