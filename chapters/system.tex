% !TeX root = ../main.tex

\chapter{以可佳机器人为基础的行人追踪系统}

\section{输入设备}

\subsection{Kinect}

  Kinect深度相机可以同时提供RGB图像和深度图像。

  使用RGB-D相机Kinect作为彩色图像和深度信息的输入，而Kinect的深度图像只能有效判断80厘米之外的物体的距离，且由于Kinect通过红外发射器和红外摄像头来获得深度信息，所以受阳光照射的影响较大，所以在实际使用中，Kinect深度图像可能会出现不稳定和空洞现象。

  对于Kinect的深度图像在近距离精度较低的现象，考虑在较近距离内使用2D激光进行行人的3D位置判别。对于Kinect的空洞现象，考虑使用KinectFusion算法\cite{newcombe2011kinectfusion}，将深度图像投影到RGB图像中，以进行对相机视野中场景的3D重建。

\subsection{2D激光}

  由于本文中的行人检测与追踪算法主要使用了视觉信息，所以这里2D激光主要用于建图、定位和导航。定位和导航在本文中不是主要内容，所以不再特别赘述。

\section{视觉追踪系统}

\subsection{总体架构}

\subsection{目标人物注册}
1. 使用OpenPose系统找到目标人物

给人物设定一个初始的手势，由OpenPose系统识别出人物的骨架，进而提取出视野中所有人物的姿势。如要求目标人物将一只手举起，直到机器人识别出目标人物，判断出追踪区域（Region of Interest, ROI），并提示“识别成功”，即开始追踪。

2. 建立一个判别器：根据已有的ROI作为正样本，随机提取背景作为负样本，通过在线学习拟合出一个分类器。该判别器的作用是当追踪失去目标或出错时，当再在图像中检测到一个新人物时，判断对方是否是一开始的目标人物。

\subsection{行人追踪}

1. 使用KFC和CSRT，根据“目标人物注册”中得到的ROI进行目标追踪。

KCF: 检测成功时的平均帧率：43FPS
在一段时间后框会有点歪
框的大小不变 - 不能适应物体的不同尺度。好歹它能在初始尺度上保证人是一直在中心的。

TLD：15
准确率较低，框大小会变，但经常跳动/漂移。。甚至检测到错误的位置。当遮挡和出画面时会得到错误的结果，但恢复能力很强。

CSRT：帧率：18FPS
在人物短暂出画面或者部分遮挡时有时可以恢复，有时不行。。尺度可以在一定程度上变化，但框会变小，难以恢复到开始的水准。。failure后难以recover。

MedianFlow
速度超快：270
尺度可变化。晃了一会之后框就变大了。。恢复不到位，人不在框中心。failure之后没法恢复。

MOSSE
速度超超超超快：450
人一旦出画面就没法恢复了，而且还不报错。。尺度不变，不能很好地处理遮挡。没多久框就漂了。。

主要考虑使用CSRT，但需要考虑判断是否failure及怎样recover

\subsection{目标丢失恢复}

1. 全局扫描找到行人，结合“目标人物注册”中的判别器，判断是否是目标人物。

2. 结合目标人物最后出现的位置，类似TLD？

