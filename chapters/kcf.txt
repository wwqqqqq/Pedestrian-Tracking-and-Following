  KCF算法中实验了三种核函数，包括线性核函数、多项式核函数和高斯核函数。首先使用线性核函数为例，在线性回归函数中使用岭回归（Ridge Regression）以得到一个简单的闭式解。通过训练得到一个函数$f(\vec{z})=\vec{w}^T\vec{z}$，使得样本$\vec{x}_i$及其回归目标$y_i$之间的方差最小，即：
$$\min_{\vec{w}}\sum_i (f(\vec{x_i})-y_i)^2+\lambda \lVert\vec{w}\rVert^2$$

  类似SVM，这里的$\lambda$是用于防止过拟合的正则化参数。由于岭回归的性质，上式可以得到一个简单的闭式解$\vec{w}=(X^TX+\lambda I)^{-1}X^T\vec{y}$。其中矩阵$X$的第$i$行为$\vec{x}_i$，向量$\vec{y}$的第$i$个元素为其回归目标$y_i$。$I$为单位矩阵。上面已经提过，为了提高运算效率，将计算转到傅里叶域中进行，故数据一般都以复数计算，所以将矩阵装置替换为共轭转置，得到：
$$\vec{w}=(X^HX+\lambda I)^{-1}X^H\vec{y}$$

  这个公式已经可以进行对$\vec{w}$的计算了，但是由于计算中包括矩阵求逆，计算量很大，难以符合实时性要求。\citet{henriques2015high}巧妙地利用了循环矩阵的性质和离散傅里叶变换，将该运算简化成只需要元素点乘的版本，大大提高了运行速度。具体推导如下：

  以单通道一维信号输入为例，对于一个$n\times1$的向量$\vec{x}$，以它为生成向量计算一个循环矩阵$X$：

$$
X = C(\vec{x}) =
\left[
\begin{matrix}
 x_1      & x_2      & x_3      & \cdots & x_n     \\
 x_n      & x_3      & x_2      & \cdots & x_{n-1} \\
 x_{n-1}  & x_n      & x_1      & \cdots & x_{n-2} \\
 \vdots   & \vdots   & \ddots   & \ddots & \vdots  \\
 x_2      & x_3      & x_4      & \cdots & x_1     \\
\end{matrix}
\right]
$$

  循环矩阵的模式是确定的，并完全由它的生成向量向量$\vec{x}$决定。该矩阵的每一行都是$\vec{x}$的一种循环位移向量。可以相当于将正样本图像向上/下移动不同的像素来得到新的样本，类似于MIL分类器中在正样本周围邻域取正样本包的做法，相当于数据增光，使分类器的效果更好。

  除此之外，循环矩阵还有一个重要的特性，即对任意生成向量$\vec{x}$，所有循环矩阵都可被离散傅里叶变换（DFT）对角化，即：
$$X = F {\rm diag}(\hat{\vec{x}}) F^H$$

  其中$\hat{\vec{x}}$为$\vec{x}$的离散傅里叶变换，$F$为一个与$\vec{x}$无关的常数矩阵，称为离散傅里叶变换矩阵（DFT matrix），它可以用于计算所有向量的离散傅里叶变换，即$\mathcal{F}(\hat{z})=\sqrt{n}F\vec{z}$。由此，如果我们将输入数据都用其循环矩阵表示，则可以得到：
$$X^HX = F {\rm diag}(\hat{\vec{x}}^\ast)F^H F {\rm diag}(\hat{\vec{x}})F^H$$

  其中$\hat{\vec{x}}^\ast$为$\hat{\vec{x}}$的复共轭向量，由于对角矩阵是对称的，所以共轭转置的结果即为原矩阵的复共轭。此外，根据$F$的性质，$F^H F $即为单位矩阵$I$。此外，由于在对角矩阵上进行的运算是逐元素的，我们使用$\odot$表示向量或矩阵间的逐元素点乘，则上式可以简化为：
$$X^HX = F {\rm diag}(\hat{\vec{x}}^\ast \odot \hat{\vec{x}}) F^H$$

  将这个公式带入求$\vec{w}$的公式中，可以最终将$\vec{w}$的计算过程简化成：
$$\hat{\vec{w}}=\frac{\hat{\vec{x}}^\ast \odot \hat{\vec{y}}}{\hat{\vec{x}}^\ast \odot \hat{\vec{x}}+\lambda}$$

  这里的分数代表逐元素的除法。在求出$\hat{\vec{w}}$后，可以通过很简单的元素求出其的逆离散傅里叶变换。